<!DOCTYPE html>

<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<script async="" src="./js/analytics.js"></script>
	<!-- <script src="./js/jsapi" type="text/javascript"></script>
	<script type="text/javascript">google.load("jquery", "1.3.2");</script> -->
	<script type="text/javascript" charset="utf-8"
		src="https://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script>
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css"
		integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">

	<!-- The loading of KaTeX is deferred to speed up page rendering -->
	<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js"
		integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4"
		crossorigin="anonymous"></script>

	<!-- To automatically render math in text elements, include the auto-render extension: -->
	<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js"
		integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
		onload="renderMathInElement(document.body);"></script>
	<!-- Google Tag Manager -->
	<script>(function (w, d, s, l, i) {
			w[l] = w[l] || []; w[l].push({
				'gtm.start':
					new Date().getTime(), event: 'gtm.js'
			}); var f = d.getElementsByTagName(s)[0],
				j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
					'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
		})(window, document, 'script', 'dataLayer', 'GTM-WLCRH4G');</script>
	<!-- End Google Tag Manager -->
	<!-- Required meta tags -->
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
	<!-- Bootstrap CSS -->
	<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css"
		integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
	<link href="style.css" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i"
		rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,300italic,400italic,700italic"
		rel="stylesheet" type="text/css">

	<title>Extreme Q-Learning: MaxEnt RL Without Entropy</title>
	<meta property="og:image" content="teaser.png">
	<meta property="og:title" content="Extreme Q-Learning: MaxEnt RL Without Entropy">

</head>

<body data-new-gr-c-s-check-loaded="14.984.0" data-gr-ext-installed="">
	<!-- Google Tag Manager -->
	<script>(function (w, d, s, l, i) {
			w[l] = w[l] || []; w[l].push({
				'gtm.start':
					new Date().getTime(), event: 'gtm.js'
			}); var f = d.getElementsByTagName(s)[0],
				j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
					'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
		})(window, document, 'script', 'dataLayer', 'GTM-WLCRH4G');</script>
	<!-- End Google Tag Manager -->
	<br>
	<center>
		<div id="hero">
			<h1>Extreme Q-Learning: MaxEnt RL without Entropy</h1>
			<div class="authors">
				<table align="center" width="1030px">
					<tbody>
						<tr>
							<td align="center" width="300px">
								<center>
									<span><a href="https://divyanshgarg.com/">Divyansh
											Garg*</a><sup>1<sup></span>
								</center>
							</td>
							<td align="center" width="300px">
								<center>
									<span><a href="https://jhejna.github.io">Joey Hejna*
										</a><sup>1<sup></span>
								</center>
							</td>
							<td align="center" width="300px">
								<center>
									<span><a href="">Matthieu Geist</a><sup>2<sup></span>
								</center>
							</td>
							<td align=" center" width="300px">
								<center>
									<span><a href="https://cs.stanford.edu/~ermon/">Stefano
											Ermon</a><sup>1<sup></span>
								</center>
							</td>
						</tr>
					</tbody>
				</table>
			</div>
			<table align="center" width="700px">
				<tbody>

					<tr>
						<td align="center" width="250px">
							<center>
								<span style="font-size:20px">Stanford University<sup>1</sup></span>
								<span
									style="font-size:20px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Google<sup>2</sup></span>
							</center>
						</td>
					</tr>
					<tr>
						<td align="center" width="200px">
							<center>
								<span style="font-size:20px">*Equal Contribution</span>
							</center>
						</td>
					</tr>
				</tbody>
			</table>
			<!-- <table align="center" width="800px">
				<tbody>
					<tr>
						<td align="center" width="150px">
							<center>
								<span style="font-size:25px">Under Review <b><em></em></b></span>
								</span>
							</center>
						</td>
					</tr>
				</tbody>
			</table> -->
	</center>
	<center>
		<table style="margin-top: 20px">
			<tbody>
				<tr>
					<td>
						<center><a href="https://arxiv.org/abs/2301.02328" target="_blank" class="nav-link link"><img
									class="filter-blue" src="icons/paper_icon.svg" width="48" height="48"><br>Paper</a>
						</center>
					</td>
					<td>
						<center> <a href="https://github.com/Div99/xql" target="_blank" class="nav-link link"><img
									class="filter-blue" src="icons/github.svg" width="48" height="48"><br>Code<br></a>
						</center>
					</td>
					<!-- <td>
						<center><a
								href="https://slideslive.com/embed/presentation/38967041?embed_parent_url=https%3A%2F%2Fneurips.cc%2Fvirtual%2F2021%2Fposter%2F26537&embed_container_origin=https%3A%2F%2Fneurips.cc&embed_container_id=presentation-embed-38967041&auto_load=true&auto_play=false&zoom_ratio=&disable_fullscreen=false&locale=en&vertical_enabled=true&vertical_enabled_on_mobile=false&allow_hidden_controls_when_paused=true&fit_to_viewport=true&user_uuid=2f7f8b9e-d23a-478f-ad00-f0905aa4836d"
								target="_blank" class="nav-link link"><img class="filter-blue" src="icons/youtube.svg"
									width="48" height="48"><br>Talk<br></a></center>
					</td> -->
				</tr>
			</tbody>
		</table>
	</center><br>
	</div>


	<table align="center" width="800px">
		<tbody>
			<tr>
				<td width="400px">
					<center>
						<img class="img" src="diagram.svg" style="width:700px;height:auto;"><br>
					</center>
				</td>
			</tr>
			<tr>
				<td>
					<center>
						<center>
							<div style="font-size:20px;"><i><span style="color: red" class="bold">TLDR:</span> A novel
									framework
									for
									Q-learning that models the maximal
									soft-values without needing to sample from a policy.</div>
						</center>
					</center>
				</td>
			</tr>
		</tbody>
	</table>

	<br>
	<hr>
	<center>
		<h1>Abstract</h1>
	</center>
	<table align="center" width="850px">
		<tbody>
			<tr>
				<td>
				</td>
			</tr>
		</tbody>
	</table>
	<p class="mt-3 ml-3 mr-3">
		Modern Deep Reinforcement Learning (RL) algorithms require estimates of the maximal Q-value, which are difficult
		to
		compute in continuous domains with an infinite number of possible actions. In this work, we introduce a new
		update
		rule for online and offline RL which directly models the maximal value using Extreme Value Theory (EVT), drawing
		inspiration from Economics. By doing so, we avoid computing Q-values using out-of-distribution actions which is
		often a substantial source of error. Our key insight is to introduce an objective that directly estimates the
		optimal soft-value functions (LogSumExp) in the maximum entropy RL setting without needing to sample from a
		policy. <br><br>
		Using EVT, we derive our <span class=" text-primary"><strong>Extreme Q-Learning (XQL)</strong></span> framework
		and consequently online and, for the first
		time,
		offline MaxEnt Q-learning algorithms, <b><em>that do not explicitly require access to a policy or its
				entropy.</em></b>
		Our method obtains consistently strong performance in the D4RL benchmark, outperforming prior works by
		<b>10+ points</b> on some
		tasks while offering moderate improvements over SAC and TD3 on online DM Control tasks.
	</p>
	<br>

	<hr>
	<center>
		<h1>Key Idea: <b>Gumbel Regression</b></h1>
	</center>
	<br><br>
	<table align="center" width="900px">
		<tbody>
			<tr>
				<td width="300">
					<center>
						<img class="round" src="gumbel_regression.png" style="width:100%;height:auto;"><br>
					</center>
				</td>
				<td width="18" />
				<td width="400" align="left">
					<p class="font"><b style="color: red"><em>TLDR:</em></b> The core of our approach is fitting <a
							href="https://en.wikipedia.org/wiki/Gumbel_distribution">Gumbel
							distribution</a> \(\mathcal{G}(\mu, \beta)\) to the data to
						introduce <b><em>Gumbel regression (or Extremal regression)</em></b>, a new technique which
						models the
						extreme values of a distribution. <br> <br>
						This is similar to fitting a Gaussian distribution to the data, but instead of modeling the mean
						(i.e. least squares regression)
						it fits the Log-Sum-Exp or
						the Log-Partition function of the data. </p>
				</td>
			</tr>
		</tbody>
	</table>
	<br>
	<p>For a temperature \(\beta\), Gumbel regression estimates the operator \(\beta \log \mathbb{E}[e^{X/\beta}] \)
		or the Log-Partition function over samples drawn from a distribution \(X\). This is a central quantity of
		interest in
		Statistics as well as Physical Sciences, and it's accurate calculation has important applications in
		Probabilistic Modeling, Bayesian Learning and Information Theory, such as in calculating maginal
		distributions.<br><br>
		Nevertheless, it is very difficult to estimate in continuous spaces and usually assumed as an intractable
		quantity. This has led to a host of variational inference methods such as VAEs, that use approximations to
		side-step calculating it.
		Gumbel Regression enables <b><em>for the first time, exact estimation of the Log-Partition function by using
				simple
				gradient descent.</em></b><br><br>

		By controlling the temperature \(\beta\), Gumbel regression interpolates between the
		the max (\(\beta=0\)) and the mean (\(\beta=\infty\)) of a distribution \(X\), and provides a robust
		estimator for the extremal values of a distribution. Finally, Gumbel Regression admits to tight PAC
		learning bounds
		and has a bound approximation error on a finite dataset (Section 3 of the paper).
	</p>
	<br>
	<hr>
	<center>
		<h1>Approach</h1>
	</center>
	<br>
	<p>Our Gumbel regression loss function can be used to directly fit
		the Log-Sum-Exp of the Q-values, yielding the soft-optimal value function \(V^* = LogSumExp(Q)\). Then,
		we can use
		Q-iteration even in high-dimensional continuous action spaces to find the optimal MaxEnt policy. This
		general algorithm
		works well in both
		online, and offline settings. <br><br> For online RL, it can be used to extend existing algorithms like SAC and
		TD3, with
		moderate
		performance
		gains. On offline RL, it outperforms existing approaches, and obtains SOTA on D4RL benchmarks. Below we provide
		a
		high-level overview:</p><br>
	<table align="center" width="600px">
		<tbody>
			<tr>
				<td align="center">
				</td>
			</tr>
			<tr>
				<td align="center"><img class="round" style="height:600px; margin-left: 60px" src="approach.png">
				</td>
			</tr>

		</tbody>
	</table>

	<table align="center" width="800px">
		<tbody>
			<tr></tr>
		</tbody>
	</table>
	<br>
	<hr>

	<center>
		<h1>Offline Results</h1>
	</center>
	<br>

	<table align="center" width="900px">
		<tbody>
			<tr>
				<td width="600px">
					<center>
						<div style="margin: 0 auto; width: 1000px">
							<img class="img" src="compare.png" style="width:100%;height:auto;"><br>
					</center>
					</div>
				</td>
			</tr>
			<tr>
				<td width=" 300px">
					<center>
						<div style="font-size:17px; padding-bottom: 10px">
							<i>(Above) XQL reaching state of the art results on the Offline D4RL
								Benchmark<br></i>
						</div>
					</center>
				</td>
			</tr>
		</tbody>
	</table>
	<br>
	<table align="center" width="900px">
		<tbody>
			<tr>
				<td width="300">
					<!-- <center> -->
					<img class="img-banner" src="xql_franka.gif" style="width:90%;height:auto;"><br>
					<!-- </center> -->
				</td>
				<td width="300">
					<!-- <center> -->
					<img class="img-banner" src="iql_franka.gif" style="width:90%;height:auto;"><br>
					</center>
				</td>
			</tr>
			<tr>
				<td width=" 300px">
					<center>
						<div style="font-size:17px; padding-bottom: 10px">
							<i>XQL on Franka Kitchen<br></i>
						</div>
					</center>
				</td>
				<td width=" 300px">
					<center>
						<div style="font-size:17px; padding-bottom: 10px">
							<i>IQL on Franka Kitchen<br></i>
						</div>
					</center>
				</td>
			</tr>
		</tbody>
	</table>
	<br>
	<hr>

	<center>
		<h1>Online Results</h1>
	</center>
	<br>

	<table align="center" width="900px">
		<tbody>
			<tr>
				<td width="400px">
					<center>
						<img class="img" src="website_td3.png" style="width:105%;height:auto;"><br>
					</center>
				</td>
			</tr>
			<tr>
				<td width=" 300px">
					<center>
						<div style="font-size:17px; padding-bottom: 10px">
							<i>X-TD3 shows moderate gains on DM Control Tasks compared to standard TD3.<br></i>
						</div>
					</center>
				</td>
			</tr>
		</tbody>
	</table>
	<br>
	<table align="center" width="900px">
		<tbody>
			<tr>
				<td width="300">
					<center>
						<img class="img-banner" src="quad_xtd3.gif" style="width:75%;height:auto;"><br>
					</center>
				</td>
				<td width="300">
					<center>
						<img class="img-banner" src="quad_td3.gif" style="width:75%;height:auto;"><br>
					</center>
				</td>
			</tr>
			<tr>
				<td width=" 300px">
					<center>
						<div style="font-size:17px; padding-bottom: 10px">
							<i>X-TD3 on Quadruped Run (Reward 437)<br></i>
						</div>
					</center>
				</td>
				<td width=" 300px">
					<center>
						<div style="font-size:17px; padding-bottom: 10px">
							<i>TD3 on Quadruped Run (Reward 293)<br></i>
						</div>
					</center>
				</td>
			</tr>
			<tr style="height: 20px;">
				<td></td>
				<td></td>
			</tr>
			<tr>
				<td width="300">
					<center>
						<img class="img-banner" src="hopper_xtd3_2q.gif" style="width:75%;height:auto;"><br>
					</center>
				</td>
				<td width="300">
					<center>
						<img class="img-banner" src="hopper_td3_2q.gif" style="width:75%;height:auto;"><br>
					</center>
				</td>
			</tr>
			<tr>
				<td width=" 300px">
					<center>
						<div style="font-size:17px; padding-bottom: 10px">
							<i>X-TD3 on Hopper Hop (Reward 71)<br></i>
						</div>
					</center>
				</td>
				<td width=" 300px">
					<center>
						<div style="font-size:17px; padding-bottom: 10px">
							<i>TD3 on Hopper Hop (Reward 20)<br></i>
						</div>
					</center>
				</td>
			</tr>
		</tbody>
	</table>
	<br>
	<hr>


	<center>
		<h1>Citation</h1>
	</center>
	<table align="center" width="1000px">
		<tbody>
			<tr>
				<td><span style="font-size:14pt">
					</span>
				</td>
			</tr>
		</tbody>
	</table>
	<pre>
@article{
	garg2022extreme,
	title={Extreme Q-Learning: MaxEnt Reinforcement Learning Without Entropy},
	url = {https://arxiv.org/abs/2301.02328},
  	author = {Garg, Divyansh and Hejna, Joey and Geist, Matthieu and Ermon, Stefano},
	publisher = {arXiv},
  	year = {2023},
	}
</pre>
	<br><br>
	<br><br>
	<script>
		(function (i, s, o, g, r, a, m) {
			i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
				(i[r].q = i[r].q || []).push(arguments)
			}, i[r].l = 1 * new Date(); a = s.createElement(o),
				m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
		})(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
		ga('create', 'UA-75863369-1', 'auto');
		ga('send', 'pageview');
	</script>
</body>

</html>